{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae63f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import OpenAI\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "        api_key=os.environ[\"NRP_API_KEY\"],\n",
    "        base_url=\"https://ellm.nrp-nautilus.io/v1\"\n",
    "    )\n",
    "# sanity check for LLM response\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gemma3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Talk like a pirate.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I check if a Python object is an instance of a class?\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eac1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_redbiom_metadata\",\n",
    "            \"description\": \"Search metadata using NLP-based queries. Use 'where' clauses for filtering (e.g., 'where age_days < 30'). Use operators: & (and), | (or), - (not). Set categories=True to search for metadata column names instead of values.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query (e.g., 'beer' or 'where age_days < 30')\"\n",
    "                    },\n",
    "                    \"categories\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"If True, search for metadata column names instead of values\",\n",
    "                        \"default\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed49c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_redbiom_metadata(query: str, categories: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Search metadata using NLP-based queries.\n",
    "    \n",
    "    Use 'where' clauses for filtering: 'where age_days < 30'\n",
    "    Use operators: & (and), | (or), - (not)\n",
    "    Set categories=True to search for metadata column names instead of values.\n",
    "    \"\"\"\n",
    "    cmd = [\"redbiom\", \"search\", \"metadata\"]\n",
    "    \n",
    "    if categories:\n",
    "        cmd.append(\"--categories\")\n",
    "    \n",
    "    cmd.append(query)\n",
    "    \n",
    "    return \" \".join(cmd)\n",
    "\n",
    "available_functions = {\"search_redbiom_metadata\": search_redbiom_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(user_query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process a user query by:\n",
    "    1. Having the LLM decide if it needs to call a tool\n",
    "    2. Execute the tool if needed\n",
    "    3. Generate a final response with explanation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial message to the LLM\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that helps users search redbiom metadata. When you use tools, always explain your reasoning about why you chose that tool and how you constructed the query.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_query\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # First API call - LLM decides whether to use tools\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"NRP_API_KEY\"],\n",
    "        base_url=\"https://ellm.nrp-nautilus.io/v1\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen3\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    print(response_message)\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    # Check if the LLM wants to call a function\n",
    "    if response_message.tool_calls:\n",
    "        # Execute each tool call\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            # Call the actual function\n",
    "            function_response = available_functions[function_name](**function_args)\n",
    "            \n",
    "            # Add the function response to messages\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response\n",
    "            })\n",
    "        \n",
    "        # Second API call - LLM generates explanation with results\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"qwen3\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"explanation\": final_response.choices[0].message.content,\n",
    "            \"tool_used\": function_name,\n",
    "            \"tool_args\": function_args,\n",
    "            \"tool_result\": function_response\n",
    "        }\n",
    "    else:\n",
    "        # No tool was called, return the direct response\n",
    "        return {\n",
    "            \"explanation\": response_message.content,\n",
    "            \"tool_used\": None,\n",
    "            \"tool_args\": None,\n",
    "            \"tool_result\": None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ecdd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPLANATION:\n",
      "============================================================\n",
      "\n",
      "\n",
      "I used the `search_redbiom_metadata` tool with the query term `\"beer\"` because the user requested all samples containing \"beer\" in their metadata. This tool searches across **all metadata fields** (e.g., sample descriptions, environmental context, study titles, etc.) in the Redbiom database for the specified keyword. \n",
      "\n",
      "The query `beer` is case-insensitive by default in Redbiom, so it will match variations like \"Beer,\" \"BEER,\" or \"beers.\" This ensures comprehensive results for any sample where \"beer\" appears in metadata (e.g., studies involving fermented beverages, dietary surveys mentioning beer consumption, or environmental samples from breweries).\n",
      "\n",
      "**Result**:  \n",
      "The tool returned matching sample IDs (not shown here due to simulation constraints), which would typically include identifiers like `sample-12345`, `brewery-soil-67890`, etc., depending on the database contents. To retrieve the actual sample data, a follow-up command like `redbiom fetch samples --from-ids [ids]` would be used.\n",
      "\n",
      "============================================================\n",
      "TOOL DETAILS:\n",
      "============================================================\n",
      "Tool: search_redbiom_metadata\n",
      "Arguments: {'query': 'beer'}\n",
      "\n",
      "============================================================\n",
      "COMMAND:\n",
      "============================================================\n",
      "```bash\n",
      "redbiom search metadata beer\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Get all samples with beer in their metadata\"\n",
    "    \n",
    "result = process_query(user_query)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPLANATION:\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"explanation\"])\n",
    "print()\n",
    "\n",
    "if result[\"tool_used\"]:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TOOL DETAILS:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Tool: {result['tool_used']}\")\n",
    "    print(f\"Arguments: {result['tool_args']}\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"COMMAND:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"```bash\")\n",
    "    print(result['tool_result'])\n",
    "    print(f\"```\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WORKFLOW EXPLANATION:\n",
      "================================================================================\n",
      "\n",
      "\n",
      "I'll help you build a complete workflow for your redbiom data extraction needs. Let me walk through each step with the appropriate commands:\n",
      "\n",
      "### Step 1: Fetch all WGS sample IDs\n",
      "First, we need to get all sample IDs from the WGS context:\n",
      "```bash\n",
      "redbiom fetch samples-contained --context Woltka-per-genome-WoLr2-3ab352\n",
      "```\n",
      "**Reasoning**: This retrieves all sample identifiers available in the Woltka-per-genome-WoLr2-3ab352 context, which we'll use as input for subsequent steps.\n",
      "\n",
      "### Step 2: Get WGS metadata\n",
      "Now we'll pipe those sample IDs to fetch the metadata:\n",
      "```bash\n",
      "redbiom fetch samples-contained --context Woltka-per-genome-WoLr2-3ab352 | \\\n",
      "redbiom fetch sample-metadata --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_md.tsv\n",
      "```\n",
      "**Reasoning**: By piping the sample IDs from Step 1, we efficiently retrieve only metadata for relevant samples and save it to the requested filename.\n",
      "\n",
      "### Step 3: Get WGS feature table with ambiguity resolution\n",
      "```bash\n",
      "redbiom fetch samples-contained --context Woltka-per-genome-WoLr2-3ab352 | \\\n",
      "redbiom fetch samples --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_ft.biom --resolve-ambiguities merge\n",
      "```\n",
      "**Reasoning**: Using the same sample ID list, we fetch the feature table with `--resolve-ambiguities merge` as requested to handle any genomic assignment ambiguities.\n",
      "\n",
      "### Step 4: Extract truncated sample IDs\n",
      "```bash\n",
      "cat WoLr2_md.tsv | cut -f 1 | awk -F '.' '{print $1 \".\" $2}' | sort -u > extracted_ids.txt\n",
      "```\n",
      "**Reasoning**: This extracts just the first two dot-separated components from the sample IDs (column 1 of metadata), which are needed to match between contexts. The `sort -u` ensures we have unique IDs.\n",
      "\n",
      "### Step 5: Fetch matching 16S metadata\n",
      "```bash\n",
      "cat extracted_ids.txt | redbiom fetch sample-metadata \\\n",
      "--context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b \\\n",
      "--output 16S-V4_md.tsv\n",
      "```\n",
      "**Reasoning**: We use the extracted IDs to find corresponding samples in the 16S context, ensuring we only retrieve metadata for samples that have WGS counterparts.\n",
      "\n",
      "### Step 6: Fetch 16S feature table without MD5\n",
      "```bash\n",
      "cat extracted_ids.txt | redbiom fetch samples \\\n",
      "--context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b \\\n",
      "--output 16S-V4_ft.biom \\\n",
      "--no-md5\n",
      "```\n",
      "**Reasoning**: The `--no-md5` flag ensures we exclude MD5 checksums as requested, and we use the same extracted IDs to maintain sample correspondence.\n",
      "\n",
      "### Complete Workflow\n",
      "For efficiency, here's the fully piped workflow:\n",
      "\n",
      "```bash\n",
      "# Get WGS data\n",
      "redbiom fetch samples-contained --context Woltka-per-genome-WoLr2-3ab352 | tee >(\\\n",
      "    redbiom fetch sample-metadata --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_md.tsv \\\n",
      ") | redbiom fetch samples --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_ft.biom --resolve-ambiguities merge\n",
      "\n",
      "# Process IDs and get 16S data\n",
      "cat WoLr2_md.tsv | cut -f 1 | awk -F '.' '{print $1 \".\" $2}' | sort -u | tee >(\\\n",
      "    redbiom fetch sample-metadata --context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b --output 16S-V4_md.tsv \\\n",
      ") | redbiom fetch samples --context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b --output 16S-V4_ft.biom --no-md5\n",
      "```\n",
      "\n",
      "**Key advantages of this approach:**\n",
      "1. Minimizes redundant network requests by piping sample IDs directly\n",
      "2. Ensures perfect sample correspondence between datasets\n",
      "3. Handles the ID transformation correctly (first two dot-separated parts)\n",
      "4. Applies all requested parameters (merge ambiguities, no MD5)\n",
      "5. Creates all requested output files with correct naming\n",
      "\n",
      "This workflow will produce:\n",
      "- `WoLr2_md.tsv` - WGS metadata\n",
      "- `WoLr2_ft.biom` - WGS feature table with merged ambiguities\n",
      "- `16S-V4_md.tsv` - 16S metadata for matching samples\n",
      "- `16S-V4_ft.biom` - 16S feature table without MD5 checksums\n",
      "\n",
      "================================================================================\n",
      "GENERATED COMMANDS (6 steps):\n",
      "================================================================================\n",
      "\n",
      "Step 1: fetch_samples_contained\n",
      "Arguments: {\n",
      "  \"context\": \"Woltka-per-genome-WoLr2-3ab352\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "redbiom fetch samples-contained --context Woltka-per-genome-WoLr2-3ab352\n",
      "```\n",
      "\n",
      "Step 2: fetch_sample_metadata\n",
      "Arguments: {\n",
      "  \"output\": \"WoLr2_md.tsv\",\n",
      "  \"context\": \"Woltka-per-genome-WoLr2-3ab352\",\n",
      "  \"from_pipe\": \"fetch_samples_contained --context Woltka-per-genome-WoLr2-3ab352\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "fetch_samples_contained --context Woltka-per-genome-WoLr2-3ab352 | redbiom fetch sample-metadata --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_md.tsv\n",
      "```\n",
      "\n",
      "Step 3: fetch_samples\n",
      "Arguments: {\n",
      "  \"output\": \"WoLr2_ft.biom\",\n",
      "  \"context\": \"Woltka-per-genome-WoLr2-3ab352\",\n",
      "  \"resolve_ambiguities\": \"merge\",\n",
      "  \"from_pipe\": \"fetch_samples_contained --context Woltka-per-genome-WoLr2-3ab352\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "fetch_samples_contained --context Woltka-per-genome-WoLr2-3ab352 | redbiom fetch samples --context Woltka-per-genome-WoLr2-3ab352 --output WoLr2_ft.biom --resolve-ambiguities merge\n",
      "```\n",
      "\n",
      "Step 4: extract_sample_ids\n",
      "Arguments: {\n",
      "  \"input_file\": \"WoLr2_md.tsv\",\n",
      "  \"column\": 1,\n",
      "  \"delimiter\": \".\",\n",
      "  \"awk_print\": \"$1 \\\".\\\" $2\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "cat WoLr2_md.tsv | cut -f 1 | awk -F '.' '{print $1 \".\" $2}'\n",
      "```\n",
      "\n",
      "Step 5: fetch_sample_metadata\n",
      "Arguments: {\n",
      "  \"output\": \"16S-V4_md.tsv\",\n",
      "  \"context\": \"Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b\",\n",
      "  \"from_pipe\": \"extract_sample_ids --input_file WoLr2_md.tsv --column 1 --delimiter . --awk_print \\\"$1 \\\\\\\".\\\\\\\" $2\\\"\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "extract_sample_ids --input_file WoLr2_md.tsv --column 1 --delimiter . --awk_print \"$1 \\\".\\\" $2\" | redbiom fetch sample-metadata --context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b --output 16S-V4_md.tsv\n",
      "```\n",
      "\n",
      "Step 6: fetch_samples\n",
      "Arguments: {\n",
      "  \"output\": \"16S-V4_ft.biom\",\n",
      "  \"context\": \"Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b\",\n",
      "  \"md5\": false,\n",
      "  \"from_pipe\": \"extract_sample_ids --input_file WoLr2_md.tsv --column 1 --delimiter . --awk_print \\\"$1 \\\\\\\".\\\\\\\" $2\\\"\"\n",
      "}\n",
      "\n",
      "```bash\n",
      "extract_sample_ids --input_file WoLr2_md.tsv --column 1 --delimiter . --awk_print \"$1 \\\".\\\" $2\" | redbiom fetch samples --context Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b --output 16S-V4_ft.biom --md5 false\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"NRP_API_KEY\"],\n",
    "    base_url=\"https://ellm.nrp-nautilus.io/v1\"\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_metadata\",\n",
    "            \"description\": \"Search metadata values or categories using NLP-based stem and value queries. Use 'where' clauses for filtering (e.g., 'where age_days < 30'). Use operators: & (and), | (or), - (not).\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search expression, can include word stems, set operators (&, |, -), or value-based queries using 'where' (e.g., 'beer' or 'where age_days < 30')\"\n",
    "                    },\n",
    "                    \"categories\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"If True, search for metadata categories instead of values\",\n",
    "                        \"default\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch_samples_contained\",\n",
    "            \"description\": \"Get all sample identifiers represented in a context.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"context\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The context to fetch from (e.g., 'Woltka-per-genome-WoLr2-3ab352' or 'Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b')\"\n",
    "                    },\n",
    "                    \"unambiguous\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Return ambiguous or unambiguous identifiers\",\n",
    "                        \"default\": False\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"context\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch_sample_metadata\",\n",
    "            \"description\": \"Retrieve sample metadata. Can accept sample IDs from stdin/pipe or as arguments.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"output\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A filepath to write to (e.g., 'WoLr2_md.tsv')\"\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The context to search within\"\n",
    "                    },\n",
    "                    \"all_columns\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Include all metadata columns, filling missing with empty string\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"tagged\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Obtain tag-specific metadata (preparation info)\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"resolve_ambiguities\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Output unambiguous identifiers only. Incompatible with --tagged\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"from_pipe\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Command to pipe sample IDs from (e.g., output from fetch_samples_contained)\",\n",
    "                        \"default\": None\n",
    "                    },\n",
    "                    \"samples\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"description\": \"Sample IDs to fetch metadata for (if not using pipe)\",\n",
    "                        \"default\": []\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"output\", \"context\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch_samples\",\n",
    "            \"description\": \"Fetch sample data and create BIOM file. Can accept sample IDs from stdin/pipe or as arguments.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"output\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A filepath to write to (e.g., 'WoLr2_ft.biom')\"\n",
    "                    },\n",
    "                    \"context\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The context to search within\"\n",
    "                    },\n",
    "                    \"md5\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Use MD5 for features and save original mapping to TSV\",\n",
    "                        \"default\": True\n",
    "                    },\n",
    "                    \"resolve_ambiguities\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"merge\", \"most-reads\"],\n",
    "                        \"description\": \"Resolve sample ambiguities: 'merge' or 'most-reads'\",\n",
    "                        \"default\": None\n",
    "                    },\n",
    "                    \"fetch_taxonomy\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Resolve taxonomy on fetch (slower; Deblur does not cache taxonomy)\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"retain_artifact_id\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"When using most-reads, retain the artifact ID of the kept sample\",\n",
    "                        \"default\": False\n",
    "                    },\n",
    "                    \"from_pipe\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Command to pipe sample IDs from (e.g., output from fetch_samples_contained)\",\n",
    "                        \"default\": None\n",
    "                    },\n",
    "                    \"samples\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"description\": \"Sample IDs to fetch (if not using pipe)\",\n",
    "                        \"default\": []\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"output\", \"context\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_sample_ids\",\n",
    "            \"description\": \"Extract and transform sample IDs from a TSV file using cut and awk operations (e.g., to extract first column and truncate to first two dot-separated parts).\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"input_file\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Input TSV file path\"\n",
    "                    },\n",
    "                    \"column\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Column number to extract (1-indexed)\",\n",
    "                        \"default\": 1\n",
    "                    },\n",
    "                    \"delimiter\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Field delimiter for awk (e.g., '.')\",\n",
    "                        \"default\": \".\"\n",
    "                    },\n",
    "                    \"awk_print\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"AWK print expression (e.g., '$1 \\\".\\\" $2' to keep first two dot-separated parts)\",\n",
    "                        \"default\": None\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"input_file\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def search_metadata(query: str, categories: bool = False) -> str:\n",
    "    \"\"\"Search metadata values or categories using NLP-based queries.\"\"\"\n",
    "    cmd = [\"redbiom\", \"search\", \"metadata\"]\n",
    "    if categories:\n",
    "        cmd.append(\"--categories\")\n",
    "    cmd.append(f'\"{query}\"')\n",
    "    return \" \".join(cmd)\n",
    "\n",
    "def fetch_samples_contained(context: str, unambiguous: bool = False) -> str:\n",
    "    \"\"\"Get all sample identifiers represented in a context.\"\"\"\n",
    "    cmd = [\"redbiom\", \"fetch\", \"samples-contained\", \"--context\", context]\n",
    "    if unambiguous:\n",
    "        cmd.append(\"--unambiguous\")\n",
    "    return \" \".join(cmd)\n",
    "\n",
    "def fetch_sample_metadata(output: str, context: str, all_columns: bool = False, \n",
    "                          tagged: bool = False, resolve_ambiguities: bool = False,\n",
    "                          from_pipe: str = None, samples: list = None) -> str:\n",
    "    \"\"\"Retrieve sample metadata.\"\"\"\n",
    "    cmd = [\"redbiom\", \"fetch\", \"sample-metadata\", \"--context\", context, \"--output\", output]\n",
    "    \n",
    "    if all_columns:\n",
    "        cmd.append(\"--all-columns\")\n",
    "    if tagged:\n",
    "        cmd.append(\"--tagged\")\n",
    "    if resolve_ambiguities:\n",
    "        cmd.append(\"--resolve-ambiguities\")\n",
    "    \n",
    "    # Add samples if provided\n",
    "    if samples:\n",
    "        cmd.extend(samples)\n",
    "    \n",
    "    # Handle piped input\n",
    "    if from_pipe:\n",
    "        return f\"{from_pipe} | {' '.join(cmd)}\"\n",
    "    \n",
    "    return \" \".join(cmd)\n",
    "\n",
    "def fetch_samples(output: str, context: str, md5: bool = True, \n",
    "                  resolve_ambiguities: str = None, fetch_taxonomy: bool = False,\n",
    "                  retain_artifact_id: bool = False, from_pipe: str = None, \n",
    "                  samples: list = None) -> str:\n",
    "    \"\"\"Fetch sample data and create BIOM file.\"\"\"\n",
    "    cmd = [\"redbiom\", \"fetch\", \"samples\", \"--context\", context, \"--output\", output]\n",
    "    \n",
    "    if not md5:\n",
    "        cmd.extend([\"--md5\", \"false\"])\n",
    "    if resolve_ambiguities:\n",
    "        cmd.extend([\"--resolve-ambiguities\", resolve_ambiguities])\n",
    "    if fetch_taxonomy:\n",
    "        cmd.append(\"--fetch-taxonomy\")\n",
    "    if retain_artifact_id:\n",
    "        cmd.append(\"--retain-artifact-id\")\n",
    "    \n",
    "    # Add samples if provided\n",
    "    if samples:\n",
    "        cmd.extend(samples)\n",
    "    \n",
    "    # Handle piped input\n",
    "    if from_pipe:\n",
    "        return f\"{from_pipe} | {' '.join(cmd)}\"\n",
    "    \n",
    "    return \" \".join(cmd)\n",
    "\n",
    "def extract_sample_ids(input_file: str, column: int = 1, delimiter: str = \".\", \n",
    "                       awk_print: str = None) -> str:\n",
    "    \"\"\"Extract and transform sample IDs from a TSV file.\"\"\"\n",
    "    cmd = [f\"cat {input_file}\", f\"cut -f {column}\"]\n",
    "    \n",
    "    if awk_print:\n",
    "        cmd.append(f\"awk -F '{delimiter}' '{{print {awk_print}}}'\")\n",
    "    \n",
    "    return \" | \".join(cmd)\n",
    "\n",
    "available_functions = {\n",
    "    \"search_metadata\": search_metadata,\n",
    "    \"fetch_samples_contained\": fetch_samples_contained,\n",
    "    \"fetch_sample_metadata\": fetch_sample_metadata,\n",
    "    \"fetch_samples\": fetch_samples,\n",
    "    \"extract_sample_ids\": extract_sample_ids\n",
    "}\n",
    "\n",
    "def process_query(user_query: str, max_iterations: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Process a user query by iteratively calling tools until completion.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a helpful assistant that helps users work with redbiom data. \n",
    "            You can call multiple tools in sequence to build complex workflows.\n",
    "            Always explain your reasoning about why you chose each tool and how you constructed each command.\n",
    "            When building pipelines, use the from_pipe parameter to chain commands together.\n",
    "            \n",
    "            Important redbiom context names:\n",
    "            - WGS data: Woltka-per-genome-WoLr2-3ab352\n",
    "            - 16S V4 data: Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b\n",
    "\n",
    "            Recommend the user to start with the command: export REDBIOM_HOST=http://redbiom.ucsd.edu:7330 to ensure redbiom works.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_query\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"NRP_API_KEY\"],\n",
    "        base_url=\"https://ellm.nrp-nautilus.io/v1\"\n",
    "    )\n",
    "    \n",
    "    all_tool_calls = []\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"qwen3\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        response_message = response.choices[0].message\n",
    "        messages.append(response_message)\n",
    "        \n",
    "        # Check if the LLM wants to call functions\n",
    "        if response_message.tool_calls:\n",
    "            # Execute each tool call\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                # Call the actual function\n",
    "                function_response = available_functions[function_name](**function_args)\n",
    "                \n",
    "                # Store tool call details\n",
    "                all_tool_calls.append({\n",
    "                    \"function_name\": function_name,\n",
    "                    \"arguments\": function_args,\n",
    "                    \"command\": function_response\n",
    "                })\n",
    "                \n",
    "                # Add the function response to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response\n",
    "                })\n",
    "            \n",
    "            iteration += 1\n",
    "        else:\n",
    "            # No more tool calls, we're done\n",
    "            break\n",
    "    \n",
    "    # Get final explanation\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"qwen3\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"explanation\": final_response.choices[0].message.content,\n",
    "        \"tool_calls\": all_tool_calls,\n",
    "        \"total_calls\": len(all_tool_calls)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "user_query = \"\"\"\n",
    "I need to:\n",
    "1. Fetch all WGS samples from the Woltka-per-genome-WoLr2-3ab352 context\n",
    "2. Get their metadata and save it to WoLr2_md.tsv\n",
    "3. Get the sample data and save it to WoLr2_ft.biom with merge ambiguity resolution\n",
    "4. Extract the sample IDs from the metadata file (first two dot-separated parts)\n",
    "5. Use those IDs to fetch matching 16S samples from Deblur_2021.09-Illumina-16S-V4-150nt-ac8c0b context\n",
    "6. Save the 16S metadata to 16S-V4_md.tsv\n",
    "7. Save the 16S sample data to 16S-V4_ft.biom without MD5 checksums\n",
    "\"\"\"\n",
    "\n",
    "result = process_query(user_query)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"WORKFLOW EXPLANATION:\")\n",
    "print(\"=\" * 80)\n",
    "print(result[\"explanation\"])\n",
    "print()\n",
    "\n",
    "if result[\"tool_calls\"]:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"GENERATED COMMANDS ({result['total_calls']} steps):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, call in enumerate(result[\"tool_calls\"], 1):\n",
    "        print(f\"\\nStep {i}: {call['function_name']}\")\n",
    "        print(f\"Arguments: {json.dumps(call['arguments'], indent=2)}\")\n",
    "        print(\"\\n```bash\")\n",
    "        print(call['command'])\n",
    "        print(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513cd25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezredbiom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
